% !TeX spellcheck = en_GB

\documentclass{amsart}
\usepackage[foot]{amsaddr} % put addresses on first page
\usepackage[british]{babel}
\usepackage{geometry}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath}
\allowdisplaybreaks
\usepackage{longtable}
\usepackage{bigints}
%\usepackage{siunitx}
\usepackage{amsthm}
\usepackage{soul}
\usepackage{tikz}
\usepackage{color}
\usepackage{easyReview} % for \comment, \alert, etc.

\newcommand{\addition}[1]{#1}

\usepackage{hyperref}
\usepackage[capitalise]{cleveref}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
%

\usepackage[numbers]{natbib}
\usepackage{url} % not crucial - just used below for the URL 
\usepackage{doi}

\newcommand{\x}{\boldsymbol{X}}
\renewcommand{\b}{\hat{\beta}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\normal}{\mathcal{N}}
\newcommand{\lexp}{\underline{\text{E}}}
\newcommand{\uexp}{\overline{\text{E}}}


\keywords{high dimensional data; variable selection; Bayesian analysis; imprecise probability}

\begin{document}

\title{Robust Bayesian Analysis of Causal Inference Problems}
\author{Tathagata Basu$^1$}
\email{tathagatabasumaths@gmail.com}
\author{Matthias C.~M.~Troffaes$^2$}
\email{matthias.troffaes@durham.ac.uk}
\author{Jochen Einbeck$^{2,3}$}
\email{jochen.einbeck@durham.ac.uk}
\address{$^1$UMR CNRS 7253 Heudiasyc, Universit\'{e} de Technologie de
Compi\`{e}gne}
\address{$^2$Department of Mathematical Sciences, Durham University}
\address{$^3$Durham Research Methods Centre}

\begin{abstract}
Causal inference using observational data is an important aspect in
many fields such as epidemiology, social science, economics, etc. In
particular, our goal is to find the treatment effect on the subjects
along with the causal links between the variables and the outcome.
However, estimation for such problems are extremely 
difficult as the treatment effects may vary from subject 
to subject and modelling the underlying heterogeneity explicitly makes the 
problem practically unsolvable. Another issue we face is the 
dimensionality of the problem and we may wish to find a subset of 
explanatory variables. However, standard variable selection methods
tend to maximise the predictive performance of the outcome model only and
can also be sensitive with respect to the choice of priors, particularly 
in the case of limited information. So, in this paper, we suggest a 
robust Bayesian analysis of causal inferential methods for 
high-dimensional problems in a regressional framework. We consider
a set of spike and slab priors to obtain robust estimates for
both the treatment and outcome model. We are specifically interested 
in the importance of priors in the high dimensional causal inference
as well as the identifying the confounder variables. However, indicator
based confounder selection can be deceptive in some cases. Especially, 
when the predictor is strongly associated with either the treatment or 
the outcome. This increases the posterior expectation of the selection
indicators. To avoid that we also apply a post-hoc selection scheme
which successfully remove negligible non-zero effects from the model
attaining a sparser model. Finally, we illustrate
our result using synthetic \alert{and real} dataset.

\end{abstract}

\maketitle

\section{Introduction}\label{sec:intro}

In causal inference, we are interested in estimating the causal
effect of independent variables on a dependent variable. Ideally,
randomised trials are the most efficient way to perform this task.
However, this is not very practical for several reasons; ethical 
concerns, design cost, population size, to name a few. This
leaves us with observational studies which are usually obtained
by means collecting data though surveys or record keeping. But this
can be problematic in the presence of confounders. That is when
the variables are associated with both the treatment and the outcome.
In such cases, we need to be extra cautious as otherwise it will
lead to unwanted bias in the treatment effect estimator \cite{rosenbaum83}.
Several works have been done in order to tackle the presence of
confounder variables. One such work in the topic was 
by \citet{Robins1986ANA} where the author used  a graphical
approach for the identification of the causal parameters.
\citet{rosenbaum1985} suggested the use of a link model to estimate
the propensity scores for all individuals. Later on several other
methods have been proposed based on propensity score matching.
A brief review on such methods can be found in \cite{winship99, stuart10}.

Bayesian approach in causal effect estimation has become a popular
topic in recent days. However, one of the earlier works on this can be
found in \cite{rubin1978}. Lately with the notion of high dimensional problems, Bayesian methodologies have become
more appealing. \citet{Crainiceanu2008} proposed a bi-level 
Bayesian model averaging based method for estimating the causal 
effect. \citet{wang2015} suggested BAC (or, Bayesian adjustment for
confounding) where they use an informative prior obtained from
the treatment model and apply them on the outcome model for
estimating causal effect. Several other methods were also
proposed to tackle confounders from the point of view of Bayesian
variable selection such as: \citet{Zigler2014}, \citet{Hahn2018} etc.

In this paper we take inspiration from the approach of \citet{koch2020}, where
they proposed a bilevel spike and slab prior for causal effect 
estimation. They considered a data-driven adaptive approach to
propose their prior which reduce the variance of the causal estimate. 
In our approach,
we suggest a sensitivity analysis based approach where instead
of using a single prior, we consider a set of priors \cite{BERGER1990303}. This is particularly interesting as in
many cases, causal effect estimation can be performed through a 
meta analysis and hence robust Bayesian analysis can be beneficial
\cite{raices_cruz22} under severe uncertainty.
Moreover, for some problems we have to rely on very limited data to
perform our Bayesian analysis and choosing a data-driven prior
can lead to overfitting. Therefore, as to propose our
robust Bayesian framework,
we consider a set of continuous spike and slab priors \cite{ishwaran2005}
for confounder selection and construct a Bayesian group LASSO
\cite{xu2015}. To perform the sensitivity analysis, we consider
a set of beta priors on the covariate selection probability
of the spike and slab priors. This sensitivity analysis allows us
to investigate the regression coefficients with respect to a different
level of sparsity of the model. Following that, we consider a post-hoc
variable selection method as suggested by \citet{hahn2015}. This
ensures that we can efficiently separate the confounder variables
with others and reduce the bias of treatment effect estimation.

The rest of the paper is organised as follows. In \cref{sec:causal}
we give a formal description of causal estimation problem in the
context of linear regression. \cref{sec:bayes} is focused on the
Bayesian analysis of causal inference problems, followed by the
motivation of a robust Bayesian analysis. In \cref{sec:sim}, we
provide our result of simulation studies under different 
scenarios and in data analysis with real data in \cref{sec:data:analysis}. Finally we discuss our findings and 
conclude this paper in \cref{sec:conc}.

\section{Causal Estimation}\label{sec:causal}

Let an observational study give us the outcomes $Y=(Y_1$, \dots, $Y_n)$ along with 
corresponding treatment indicators $T=(T_1$, \dots, $T_n)$. Then the
treatment 
effect in the population is given by the expectation of the difference
in outcome between the treatment and controls. 
\begin{align}
\delta = \mathbb{E}(Y\mid T =1) - E(Y\mid T=0).
\end{align}
Similarly, individual causal
effect of the treatment $T_i$ on outcome $Y_i$ is given by:
\begin{align}
\delta_i \coloneqq (Y_i\mid T_i=1) - (Y_i\mid T_i=0).
\end{align}
That is, the difference between the outcome when $i$-th subject receives
the treatment and when $i$-th subject remain as a control. 

In theory, both of these quantities exist.
However, we can not observe $(Y_i\mid T_i=1)$ and $(Y_i\mid T_i=0)$
simultaneously for the $i$-th individual. Instead, we can estimate
average causal effect of the treatment $T$ by calculating the averaged
outcome of all the subjects those received the treatment and
all the subjects those remained as control.
\begin{align}
\hat{\delta} \coloneqq 
\frac{\sum_{i=1}^n Y_i\cdot\mathbb{I}(T_i=1) - 
	\sum_{i=1}^n Y_i\cdot\mathbb{I}(T_i=0)}{n}.
\end{align}
However, this relies on an important assumption that the treatment effect
on the $i$-th subject given that they received the treatment is
equal to the treatment effect when they remain as the control
\cite{winship99}.

\subsection{Regression Model}
Regression methods are widely used in causal effect estimation. The
main idea behind these regression methods is to remove the
correlation between the treatment indicator and the error term
\cite{winship99,HECKMAN1985}. To do so, we rely on $p$ different observed quantities
or predictors denoted by $X\coloneqq$ $[X_1$, \dots, $X_n]^T$. Now, let
$\beta \coloneqq (\beta_1$, \dots, $\beta_p)$ denotes the vector of regression
coefficients. Then we can define a linear model for the outcome
so that
\begin{equation}
    Y_i = \beta_{T} T_i + \beta_0 + X_i\beta + \epsilon_i
\end{equation}
where $\epsilon_i\sim \mathcal{N}(0, \sigma^2)$. Clearly, when
the underlying true outcome model is linear,
\begin{equation}
    \delta = \beta_{T}\quad\text{and hence } 
    \hat{\delta} - \delta = \hat{\beta}_T - \beta_T.
\end{equation}
\begin{figure}
	\centering
	\begin{tikzpicture}[params/.style={circle, draw=green!60, fill=green!5, very thick, minimum size=7mm}]
	\node (1) at (0,0) {Treatment ($T$)};
	\node (2) [right = of 1] {Outcome ($Y$)};
	\node (4) [below = of 1] {Predictors ($X$)};
	
	\path (1) edge[->]  (2);
	\path (1) edge[<-]  (4);
	\path (2) edge[<-] (4);
	\end{tikzpicture}
	\caption{Confounding in causal models.}
	\label{fig:confounding}
\end{figure}

In the presence of confounders we also need to consider the
association between the treatment indicators and the predictors.
\citet{koch2020} suggested the use of a probit link function to 
construct the regression model. This way, we can
specify the conditional probability that subject $i$ receives the treatment through a linear model. 
That is, for another vector of regression coefficients 
$\gamma\coloneqq(\gamma_1, \cdots, \gamma_p)$ we define
\begin{align}
    P(T_i=1\mid X_i) \coloneqq \Phi(\gamma_0+X_i\gamma)
\end{align}
where $\Phi(\cdot)$ denotes the cumulative distribution function
of a standard normal distribution.

This allows us to define intermediate latent variables as suggested
by \citet{albert93}
\begin{equation}
	T_i^* = \gamma_0 + X_i\gamma +u_i
\end{equation}
where, $u_i\sim\mathcal{N}(0,1)$. Therefore, $T_i=1$ if $T_i^*>0$ and
$T_i=0$ if $T_i^*\le0$. 

Now, following the approach of \citet{koch2018}, we define an adjusted
output vector $W\coloneqq(Y, T^*)^T$ and corresponding $2n\times(2p+3)$ dimensional design matrix
\begin{align}
    Z &=
    \begin{bmatrix}
     X_O & 0 \\
     0 & X_T
    \end{bmatrix},
\end{align}
where, $X_O = [T, 1_n, X]$ and $X_T = [1_n, X]$. Then, assuming a
Gaussian error term, we have the following likelihood distribution
\begin{align}
W\mid Z, \alpha, \beta, \gamma, \sigma^2 \sim\normal\left(Z\nu, \Sigma\right)\label{eq:like:group},
\end{align}
where $\nu = (\beta_T, \beta_0, \beta, \gamma_0, \gamma)^T$ and
\begin{align}
\Sigma &=
\begin{bmatrix}
\sigma^2{I}_n & 0 \\
0 & {I}_n
\end{bmatrix}.
\end{align}


\section{Bayesian Causal Estimation}\label{sec:bayes}

The likelihood formation given by \cref{eq:like:group} gives us
a foundation for Bayesian group LASSO 
\cite{xu2015} type model and look into the posterior selection
probability associated with the $j$-th predictor. There are several
ways to construct spike and slab priors which achieve 
variable selection. In our case, we consider a continuous type
\cite{ishwaran2005} prior for faster posterior
computation.


\subsection{Hierarchical model}

Let, $\pi_j$ denote the prior probability that the $j$-th
predictor is not associated with either the outcome or the 
treatment. That is, 
\begin{equation}
	\pi_j = P\left((\beta_j,\gamma_j)=(0,0)\right).
\end{equation}
Then we can define a spike and slab group LASSO so that:
for $1\le j\le p$,
\begin{align}
(\beta_j,\gamma_j)^T \mid \pi_{j}, \sigma^2 &\sim 
(1-\pi_{j})\normal\left( (0,0)^T, 
\tau_1^2\begin{bmatrix}
\sigma^2 & 0 \\
0 & 1
\end{bmatrix}\right)
+ \pi_{j} \normal\left(0, 
\tau_0^2\begin{bmatrix}
\sigma^2 & 0 \\
0 & 1
\end{bmatrix}\right)\\
%\beta_T, \beta_0\mid \sigma^2 &\sim \normal(0, \sigma^2)\\
%\gamma_0 &\sim \normal(0,1)\\
\sigma^2&\sim \text{InvGamma}(a, b)\\
\pi_{j} &\sim\text{Beta}\left(sq_j, s(1-q_j)\right).
\end{align}

We fix sufficiently small $\tau^2_0$
$(1\gg\tau_0^2>0)$ so that  $(\beta_j, \gamma_j) = (0,0)$ has its probability mass 
concentrated around zero. Therefore, this represents the spike component of our prior specification. 
To construct the slab component, we consider $\tau_1^2$ to be large so that 
$\tau_1^2\ge 1$. This allows the prior for $(\beta_j, \gamma_j)\not=(0,0)$ to be flat.

As mentioned earlier, $\pi_j$ is used as the rejection probability
of the $j$-th predictor and we use a set beta priors to specify 
these rejection probabilities where  $q_j$ represents our prior expectation of the rejection probability ($\pi_j$) and `$s$' acts as 
a concentration parameter.
For the intercept terms of the outcome model and the causal effect, 
we consider a sufficiently flat prior so that 
$\beta_0. \beta_T\sim \normal(0,\sigma^2)$. Similarly, for the
intercept term in the treatment model, we consider 
$\gamma_0\sim \normal(0,1)$. 



\begin{figure}
	\centering
	\begin{tikzpicture}[params/.style={circle, draw=black!60, very thick, minimum size=7mm},
	hyper/.style={circle, draw=black!60, fill=black!20, thick, minimum size=7mm},
	post/.style={circle, draw=black!60, fill=green!20, thick, minimum size=7mm},
	latent/.style={rectangle, draw=black!60, fill=black!10, dashed, minimum size=7mm},
	data/.style={rectangle, draw=black!60, thick, minimum size=8mm}]
	\node[params] (1) at (0,0) {$\pi$};
	\node[data] (2) at (3,0) {$X$};
	\node[data] (3) at (6,0) {$T$};
	\node[params] (4) at (1.5,1.5) {$\gamma$};
	\node[latent] (5) at (4.5,1.5) {$T^*$};
	\node[params] (6) at (1.5,-1.5) {$\beta$};
	\node[data] (7) at (3.5,-1.5) {$Y$};
	\node[params] (8) at (0,-3) {$\sigma^2$};
	\node[params] (9) at (3,-3) {$\beta_0$};
	\node[params] (10) at (6,-1.5) {$\beta_T$};
	\node[hyper] (11) at (-1.5,-.8) {$s$};
	\node[hyper] (12) at (-1.5,.8) {$q$};
	\node[hyper] (13) at (-1.5,-2.2) {$a$};
	\node[hyper] (14) at (-1.5,-3.8) {$b$};
	\draw[black, dashed] (0.75,-3.7) rectangle (7,2.1);
	
	\path (1) edge[->]  (6);
	\path (1) edge[->]  (4);
	\path (8) edge[->]  (6);
	\path (6) edge[->]  (7);
	\path (2) edge[->]  (7);
	\path (2) edge[->]  (5);
	\path (5) edge[<-] (4);
	\path (5) edge[->] (3);
	\path (3) edge[->]  (7);
	\path (9) edge[->]  (7);
	\path (10) edge[->]  (7);
	\path (2) edge[dashed][->] (3);
	\path (8) edge[bend right = 60][->]  (10);
	\path (8) edge[->]  (9);
	\path (11) edge[->]  (1);
	\path (12) edge[->]  (1);
	\path (13) edge[->]  (8);
	\path (14) edge[->]  (8);
	
	\end{tikzpicture}
	\caption{Probabilistic graphical representation for causal inference with Bayesian hierarchical model.}
	\label{fig:regress}
\end{figure}

\subsection{Co-variate selection}
For the co-variate selection, we look into the posterior expectation of $\pi_j$. 
We consider the $j$-th group to be active, if
\begin{align}
    \lexp (\pi_j\mid W)\coloneqq \inf_{q_j\in \mathcal{P}_j} \text{E}(\pi_j\mid W) > 1/2
\end{align}
and inactive, if
\begin{align}
    \uexp(\pi_j\mid W) \coloneqq \sup_{q_j\in \mathcal{P}_j} \text{E}(\pi_j\mid W)< 1/2.
\end{align}
We consider the rest to be indecisive. 

This way, we get a robust group selection routine. However, this type of variable 
selection includes both treatment and outcome effects at the same time. This may not be the
case in some cases especially when either treatment effect or the outcome effect is zero or
weak. To deal with such problems, we suggest the following ad-hoc method to obtain 
adjusted sparse estimate of the zero effect in a selected group.
Let $\mathcal{S}$ denote the set of active co-variates present in the model. That is,
\begin{equation}
    \mathcal{S}\coloneqq
    \left\{j : \lexp(\pi_j\mid W) > 1/2\right\}.
\end{equation}
Let $\hat{\beta}_{\mathcal{S}}(q_{\mathcal{S}})$ be the posterior means of the regression
coefficients for the non-zero outcome effects and
$\hat{\gamma}_{\mathcal{S}}(q_{\mathcal{S}})$ be the posterior means of the regression
coefficients for the non-zero treatment effects. We apply the 
``decoupled shrinkage and selection'' method proposed by \citet{hahn2015}, to obtain
the sparse estimate. To do so, we solve the following adaptive LASSO-type \cite{Zou2006}
problems

\begin{align}
    \hat{\beta}^*_{\mathcal{S}}(q_{\mathcal{S}}) &= 
    \arg\min_{\beta_{\mathcal{S}}} \frac{1}{n}\|\x_{\mathcal{S}}\hat{\beta}_{\mathcal{S}}(q_{\mathcal{S}})
    - \x_{\mathcal{S}} \beta_{\mathcal{S}}\|_2^2 + \lambda_1\sum_{j\in\mathcal{S}} 
    \frac{|\beta_j|}{|\hat{\beta}_j(q_j)|}
\end{align}
and
\begin{align}
    \hat{\gamma}^*_{\mathcal{S}}(q_{\mathcal{S}}) &= 
    \arg\min_{\gamma_{\mathcal{S}}} \frac{1}{n}\|\x_{\mathcal{S}}\hat{\gamma}_{\mathcal{S}}(q_{\mathcal{S}})
    - \x_{\mathcal{S}} \gamma_{\mathcal{S}}\|_2^2 + \lambda_1\sum_{j\in\mathcal{S}} 
    \frac{|\gamma_j|}{|\hat{\gamma}_j(q_j)|}
\end{align}
where $q_{\mathcal{S}}\in \mathcal{P}_{\mathcal{S}}$.

\subsection{Robust Bayesian Analysis}
We perform our
robust Bayesian analysis on $q\coloneqq(q_1$, \dots, $q_p)\in\mathcal{P}$, where
\begin{equation}
\mathcal{P} \coloneqq \mathcal{P}_1\times\cdots\times\mathcal{P}_p\subseteq \left(0, 1\right)^{p}.
\end{equation}



\section{Simulation Studies}\label{sec:sim}

\section{Data Analysis}\label{sec:data:analysis}

\section{Conclusion}\label{sec:conc}

\bibliographystyle{agsm}
\bibliography{basu22}
\end{document}
